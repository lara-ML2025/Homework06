{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework06\n",
    "\n",
    "Some exercises with image and audio data preparation.\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Even more practice with lists\n",
    "- Get familiar with pandas `DataFrames`\n",
    "- Practice dataset exploration and normalization/scaling\n",
    "- Set up a dataset for proper classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/audio_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/image_utils.py\n",
    "\n",
    "!wget -q https://github.com/PSAM-5020-2025F-A/Homework04/raw/main/Homework04_utils.pyc\n",
    "!wget -q https://github.com/PSAM-5020-2025F-A/Homework05/raw/main/Homework05_utils.pyc\n",
    "\n",
    "!wget -qO- https://github.com/PSAM-5020-2025F-A/5020-utils/releases/latest/download/forest-tree.tar.gz | tar xz\n",
    "!wget -qO- https://github.com/PSAM-5020-2025F-A/5020-utils/releases/latest/download/instruments.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from image_utils import make_image, get_pixels\n",
    "\n",
    "from Homework06_utils import AwesomeAudioClassifier, AwesomeImageClassifier\n",
    "\n",
    "AUDIO_PATH = \"./data/audio/instruments/test\"\n",
    "IMAGE_PATH = \"./data/image/forest-tree/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Image/Audio Classification\n",
    "\n",
    "We're going to re-visit the classification exercises from `Homework04` and `Homework05`.\n",
    "\n",
    "This exercise is a bit different though. In some ways it's the opposite of the previous exercises because we'll already have classification models ready to be used, but will have to normalize and standardize our dataset in order to run them. This is more representative of the type of work that goes into using real, pre-trained, ML models in the wild."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Models\n",
    "\n",
    "We have two `Awesome` models, one for audio classification (`AwesomeAudioClassifier`), and one for image classification (`AwesomeImageClassifier`).\n",
    "\n",
    "Unlike the classification models we set up for `Homework04` and `Homework05`, these models have more strict requirements about the shape and values of their input data. We can't run them on the files as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "Audio and Image files are in the `data/audio/` and `data/image/` directories respectively.\n",
    "\n",
    "We will use the `get_training_data()` from each of our classifiers to get the initial training data and labels for our audio and image files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Features\n",
    "\n",
    "This is the challenging part.\n",
    "\n",
    "The data returned by `get_training_data()` is a representation of the content of the audio and image files, but it hasn't been processed or normalized in order to be used by the classifier models provided.\n",
    "\n",
    "We can try to create a `DataFrame` directly from those, and it might seem like it works, but if we take a look at the result we'll see some `NaN` (Not-a-Number) values in some of the columns, and if we send that to the model it will barf and complain about having `NaN`s in the data.\n",
    "\n",
    "This happens because all of the audios and images have different sizes. Hoooray !!\n",
    "\n",
    "Welcome to Machine Learning. This is probably where most of the time in any ML project is spent: cleaning up data and making sure it has the right format, size and shape that a model expects.\n",
    "\n",
    "For this exercise it won't be too hard to fix these.\n",
    "\n",
    "Let's start with the audio files since they're one-dimensional, and once we have the audio modeling working we'll come back to the image files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#040; padding:10px; width:calc(100% - 28px)\">\n",
    "\n",
    "## Audio Data\n",
    "\n",
    "Let's run `AwesomeAudioClassifier.get_training_data()` function to get some audio data. This function returns audio data and labels from files inside a specified directory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = AwesomeAudioClassifier.get_training_data(AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Features\n",
    "\n",
    "The audio data returned is actually in the frequency domain and is not samples, so even though we can't play these audio files, we can still plot this data and will have to normalize and clean it before we can run it through our classifier.\n",
    "\n",
    "Let's take a look at this data.\n",
    "\n",
    "What are the labels ? How many records do we have ? How many features do we have in each record ? Can we plot our data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: How many records ?\n",
    "print(\"the labels are:\", set(labels))\n",
    "print(\"the amount of recordings is:\", len(labels))\n",
    "\n",
    "# TODO: How many features ?\n",
    "# the data is not yet structures as a dataframe, so we can not get the amount of features in each record by counting feature values in the first record\n",
    "# (different records can have different amounts of features)\n",
    "# creating a list of all the features length of all the recordings\n",
    "features_lengths = [len(f) for f in features]\n",
    "min_features = min(features_lengths)\n",
    "max_features = max(features_lengths)\n",
    "print(\"the records have from\",min_features, \"to\", max_features, \"features.\")\n",
    "\n",
    "# TODO: Plot some features\n",
    "first_record_features = features[0]\n",
    "plt.plot(first_record_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like data !\n",
    "\n",
    "Looks like audio frequency-domain data to be more specific.\n",
    "\n",
    "If we were to follow some of the data exploration steps we saw in class we would want to put this data in a `DataFrame` in order to get calculate some of its statistical properties, and maybe scale/normalize it before we use it in a classifier model.\n",
    "\n",
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(features)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it works, but when we look closely at the `DataFrame`, specially if we look at the features that are further to the right, we'll see our problem: `NaN` values.\n",
    "\n",
    "As previously mentioned, this happens because the length of our features is different for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Audio Data\n",
    "\n",
    "Let's fix this by making all of the feature lists have the same length. We can either pad the short ones or slice the longer ones to have the same length as the shortest feature list. The second option is preferable since padding would require adding information to the dataset and that might have side effects.\n",
    "\n",
    "So, we'll go through the lists of lists, create a list of lengths and find the smallest length.\n",
    "\n",
    "Then, we'll iterate through the lists of lists and slice all the feature lists to have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: go through the list of features and make their lengths consistent\n",
    "# creating an empty list to populate with lengths of features\n",
    "features_length = []\n",
    "for f in features:\n",
    "    features_length.append(len(f))\n",
    "print(\"features length:\",features_length)\n",
    "\n",
    "# finding the smallest length\n",
    "smallest_length = min(features_length)\n",
    "print(\"smallest length:\", smallest_length)\n",
    "\n",
    "# cropping the features longer than smallest_length and appending the cropped versions to a new list called cropped_features\n",
    "cropped_features = []\n",
    "for f in features:\n",
    "    cropped_f = f[:smallest_length]\n",
    "    cropped_features.append(cropped_f)\n",
    "    \n",
    "# checking the length of the first cropped feature, which should be 43000\n",
    "print(\"length of the first cropped feature:\",len(cropped_features[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` created using the cropped features should look more consistent now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(cropped_features)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Empty features\n",
    "\n",
    "We've removed the `NaN` values, but it seems like we have a lot of columns that are all zeros or nearly all zeros.\n",
    "\n",
    "While it's not necessary, we could also remove these in order to speed up the modeling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# sum of all columns\n",
    "display(features_df.sum())\n",
    "\n",
    "# columns where the sum is less than 100\n",
    "display((features_df.sum(axis=0) < 100))\n",
    "\n",
    "# TODO: remove columns with no information\n",
    "# getting the actual columns that are nearly all zeros\n",
    "columns_to_drop = features_df.columns[(features_df.sum(axis=0) < 100)]\n",
    "# dropping those columns\n",
    "features_df = features_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model\n",
    "\n",
    "Now that we have a `DataFrame` with consistent rows, we can fit and evaluate our model.\n",
    "\n",
    "The next cell runs the pre-defined classification model, fitting it with our `features_df` `DataFrame` and then reports the accuracy of our model.\n",
    "\n",
    "We just have to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier and report training accuracy\n",
    "AwesomeAudioClassifier.fit(features_df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale / Normalize\n",
    "\n",
    "Hmmm.... it runs, but we can do better.\n",
    "\n",
    "We saw in class that normalizing/rescaling our features can help us find actual patterns in our data. It also helps models find patterns.\n",
    "\n",
    "Try scaling the `DataFrame` using either a `MinMaxScaler` or a `StandardScaler` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: scale/normalize features\n",
    "\n",
    "# creating a scaler object\n",
    "# min_max_scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
    "std_scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "\n",
    "# applying the scaler object to our dataframe\n",
    "# features_min_max_df = min_max_scaler.fit_transform(features_df)\n",
    "features_scaled_df = std_scaler.fit_transform(features_df)\n",
    "\n",
    "# this is the scaled version of the dataframe:\n",
    "# features_min_max_df\n",
    "features_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model Again\n",
    "\n",
    "This time with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier and report training accuracy\n",
    "AwesomeAudioClassifier.fit(features_scaled_df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Do different scaling strategies influence the prediction results ? What might that tell us about our data ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">\n",
    "training accuracy with the minmax scaler: {'clarinet': 0.90476, 'guitar': 0.9, 'piano': 1.0, 'overall': 0.93492}\n",
    "\n",
    "training accuracy with standard scaler: {'clarinet': 0.90476, 'guitar': 0.9, 'piano': 1.0, 'overall': 0.93492}\n",
    "\n",
    "The MinMaxScaler transforms every feature to fit within a specific range (0 to 1), relative to the minimum and maximum values of that feature across all audio samples. Using this scaler on the DataFrame helps because it places all features on a comparable scale, preventing features with large ranges from dominating the model's training process. For instance, if one feature has values ranging from 0 to 100000000000 and another has values from 0 to 100, an unscaled model would base its decisions almost entirely on the differences in the first feature. It would nearly ignore the second one, even though that feature could be very useful for differentiating between instruments. When we scale the data, the model makes better decisions because it can evaluate all features on a level playing field.\n",
    "\n",
    "A key difference between MinMaxScaler and StandardScaler is how they handle new data that falls outside the range of the original training set. If a new data point is outside the range seen during training, MinMaxScaler will transform it to a value greater than 1 or less than 0. This happens because the scaler's range is fixed based on the minimum and maximum of the initial data. StandardScaler, on the other hand, uses the mean and standard deviation for each column to center its values at 0 and have a range of about [-3, 3]. However, this output range is not technically fixed, so new data points can be scaled to any value. In this sense, it is less sensitive to outliers than MinMaxScaler.\n",
    "\n",
    "In our case, the training accuracy improved significantly after scaling with both methods, which means that scaling was necessary. However, the prediction results did not change when using the different scaling strategies, which suggests that the data does not have extreme outliers that would give one scaler an advantage over the other.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#040; padding:10px; width:calc(100% - 28px)\">\n",
    "\n",
    "## Image Data\n",
    "\n",
    "This is a bit trickier, but only because our classifier model for images is a bit pickier. Not only do we have to ensure that all of our records have the same number of features (images have the same number of pixels), we will also have to convert the pixels into grayscale pixels.\n",
    "\n",
    "Let's start by reading the data and looking at what we get.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = AwesomeImageClassifier.get_training_data(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data\n",
    "\n",
    "What did we get in the `imgs` variable ? How many records do we have ? How many features does each record/image have ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: look at the imgs and labels variables and get some information about the data\n",
    "\n",
    "# How many imgs ?\n",
    "print(\"the number of imgs is\", len(imgs))\n",
    "\n",
    "# How many labels ?\n",
    "print(\"the labels are:\", set(labels))\n",
    "\n",
    "\n",
    "# How many records ?\n",
    "print(\"the amount of records is:\", len(labels))\n",
    "\n",
    "\n",
    "# How many features ?\n",
    "# assuming that each pixel is a feature, we need to calculare the dimensions (height x width) of each image\n",
    "# we can get this dimensions by getting the size of the image\n",
    "features_imgs = []\n",
    "for i in imgs:\n",
    "    width, height = i.size\n",
    "    num_pixels = width * height\n",
    "    features_imgs.append(num_pixels)\n",
    "min_features = min(features_imgs)\n",
    "max_features = max(features_imgs)\n",
    "\n",
    "print(\"the records have from\",min_features, \"to\", max_features, \"features (/pixels).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Image Features\n",
    "\n",
    "It seems like we have actual `PIL` image objects and their labels. \n",
    "\n",
    "This will work to our advantage because if we try to just create a `DataFrame` of the extracted pixels from these images we'll probably have a problem with missing feature values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for img in imgs:\n",
    "  features.append(get_pixels(img))\n",
    "\n",
    "print(len(features), len(features[0]), len(features[11]))\n",
    "\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Images\n",
    "\n",
    "We could follow a similar approach to how we fixed the audio data, and just slice our pixel arrays to have the same length as the shortest pixel array, but that will distort our images. Try it out to see the result, but instead of taking pixels out from the end of the image, what we really have to do is change their dimensions so they all have the same `width` and `height` before we get their pixels.\n",
    "\n",
    "There are a couple of ways to achieve this:\n",
    "- Crop: use the `image.crop()` function to cut the images.\n",
    "- Resize: use `image.resize()` to stretch/squeeze the images into specific shapes.\n",
    "\n",
    "Documentation for [`crop()`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.crop) and [`resize()`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.resize).\n",
    "\n",
    "Take a look at a few images before picking a strategy and then take a look after to see what the chosen strategy does to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: look at characteristics/dimensions of the images\n",
    "\n",
    "# looking at two random images before resizing\n",
    "display(imgs[14])\n",
    "display(imgs[8])\n",
    "\n",
    "# getting all the widths and heights to calculate the average, as the size to which we are going to resize the images\n",
    "widths = []\n",
    "heights = []\n",
    "for i in imgs:\n",
    "  width, height = i.size\n",
    "  widths.append(width)\n",
    "  heights.append(height)\n",
    "avg_width = int(sum(widths) / len(widths))\n",
    "avg_height = int(sum(heights) / len(heights))\n",
    "\n",
    "# TODO: go through the images and make their dimensions consistent\n",
    "resized_imgs = []\n",
    "new_size = (avg_width, avg_height)\n",
    "for i in imgs:\n",
    "   resized_img = i.resize(new_size)\n",
    "   resized_imgs.append(resized_img)\n",
    "\n",
    "# TODO: look at some images\n",
    "display(resized_imgs[14])\n",
    "display(resized_imgs[8])\n",
    "# (they're bigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features\n",
    "\n",
    "Now that we have images with consistent dimensions, we can extract their pixels and convert them to grayscale, so we get a nice looking `DataFrame` to send to our classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: calculate grayscale pixel values\n",
    "\n",
    "\n",
    "grayscale_pixel_values = []\n",
    "for img in resized_imgs:\n",
    "    # getting the list of (R, G, B) pixels from the current image\n",
    "    ipxs = list(img.getdata())\n",
    "    bwpxs = []\n",
    "    # calculating the grayscale value for each pixel\n",
    "    for r,g,b in get_pixels(img):\n",
    "      gval = (r + g + b) // 3\n",
    "      bwpxs.append(gval)\n",
    "    grayscale_pixel_values.append(bwpxs)\n",
    "    \n",
    "\n",
    "# TODO: look at some images with make_image()\n",
    "himg = make_image(grayscale_pixel_values[0])\n",
    "display(himg)\n",
    "\n",
    "# TODO: create DataFrame\n",
    "features_df = pd.DataFrame(grayscale_pixel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Image Model\n",
    "\n",
    "Now that we have a `DataFrame` with consistent features, we can fit and evaluate our model.\n",
    "\n",
    "The next cell runs the pre-defined classification model, fitting it with our `features_df` `DataFrame` and then reports the accuracy of our model.\n",
    "\n",
    "We just have to run it (and wait a bit because it can take up to $20$ seconds for it to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier and report training accuracy\n",
    "AwesomeImageClassifier.fit(features_df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling / Normalizing\n",
    "\n",
    "Run the classifier model again, but this time using normalized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create scaler object, scale data and re-run classification\n",
    "\n",
    "# TODO: scale/normalize features\n",
    "\n",
    "# creating a scaler object\n",
    "min_max_scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
    "# std_scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "\n",
    "# applying the scaler object to our dataframe\n",
    "features_min_max_df = min_max_scaler.fit_transform(features_df)\n",
    "# features_scaled_df = std_scaler.fit_transform(features_df)\n",
    "\n",
    "# this is the scaled version of the dataframe:\n",
    "features_min_max_df\n",
    "# features_scaled_df\n",
    "\n",
    "# Fit the classifier and report training accuracy\n",
    "AwesomeImageClassifier.fit(features_min_max_df, labels)\n",
    "# AwesomeImageClassifier.fit(features_scaled_df, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Do different scaling strategies influence the prediction results ? What might that tell us about our data ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">\n",
    "training accuracy with the minmax scaler: {'florist': 0.97917, 'forest': 1.0, 'tree': 0.825, 'overall': 0.93472}\n",
    "\n",
    "training accuracy with the standard scaler: {'florist': 0.97917, 'forest': 1.0, 'tree': 0.85, 'overall': 0.94306}\n",
    "\n",
    "The different scaling strategies did very slightly influence the prediction results, with StandardScaler performing marginally better overall. The slight performance edge of StandardScaler might indicate that centering the data around a mean of 0 was a little more effective than scaling it to a 0-1 range, but the fact that the results are so similar suggests that the data likely does not have significant outliers. </span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
